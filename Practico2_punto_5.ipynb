{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "colab": {
      "name": "Practico2 -punto 5.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7d035562"
      },
      "source": [
        "# Práctico N° 2 Análisis de Grafos - Actividad 5 y 6\n",
        "\n",
        "Integrantes: Nicolás Benjamín Ocampo, Antonela Sambuceti"
      ],
      "id": "7d035562"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "tags": [],
        "id": "646fde0c"
      },
      "source": [
        "En este práctico, trabajaremos con un dataset extraído de Twitter. La idea es emplear los conceptos de grafos vistos en clase sobre un caso real de actualidad.\n",
        "\n",
        "## Dataset\n",
        "\n",
        "El dataset consiste en un conjunto de hilos de tweets, con un total de ~150000 tweets, extraídos entre Enero y Marzo de 2021. La temática de los mismos está referida a la vacunación contra el covid-19 en Argentina.\n",
        "\n",
        "Pueden descargar el dataset del siguiente [link](https://drive.google.com/file/d/1X_qKsE8muAnom2tDX4sLlmBAO0Ikfe_G/view?usp=sharing).\n",
        "\n",
        "### Campos\n",
        "\n",
        "- **created_at:** Fecha del tweet\n",
        "- **id_str:** ID del tweet\n",
        "- **full_text:** Contenido del tweet\n",
        "- **in_reply_to_status_id:** ID del tweet inmediatamente anterior en el hilo\n",
        "- **in_reply_to_user_id:** Autor del tweet inmediatamente anterior en el hilo\n",
        "- **user.id:** Autor del tweet\n",
        "- **user_retweeters:** Lista de ID de usuarios que retweetearon el tweet\n",
        "- **sentiment:** Etiquetado manual que indica el sentimiento o intención del tweet con respecto al tweet anterior en el hilo"
      ],
      "id": "646fde0c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cf45147b"
      },
      "source": [
        "## Configuración inicial"
      ],
      "id": "cf45147b"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89be4968-fdda-4fa2-8492-86726b2b18f7",
        "outputId": "dcac4698-0bf2-4b93-8bf0-023f9f285a9e"
      },
      "source": [
        "import torch\n",
        "\n",
        "def format_pytorch_version(version):\n",
        "    return version.split('+')[0]\n",
        "\n",
        "TORCH_version = torch.__version__\n",
        "TORCH = format_pytorch_version(TORCH_version)\n",
        "\n",
        "def format_cuda_version(version):\n",
        "    return 'cu' + version.replace('.', '')\n",
        "\n",
        "CUDA_version = torch.version.cuda\n",
        "CUDA = format_cuda_version(CUDA_version)\n",
        "\n",
        "!pip install torch-scatter     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-sparse      -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-cluster     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install torch-geometric "
      ],
      "id": "89be4968-fdda-4fa2-8492-86726b2b18f7",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.10.0+cu111.html\n",
            "Requirement already satisfied: torch-scatter in /usr/local/lib/python3.7/dist-packages (2.0.9)\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.10.0+cu111.html\n",
            "Requirement already satisfied: torch-sparse in /usr/local/lib/python3.7/dist-packages (0.6.12)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy->torch-sparse) (1.19.5)\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.10.0+cu111.html\n",
            "Requirement already satisfied: torch-cluster in /usr/local/lib/python3.7/dist-packages (1.5.9)\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.10.0+cu111.html\n",
            "Requirement already satisfied: torch-spline-conv in /usr/local/lib/python3.7/dist-packages (1.2.1)\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.7/dist-packages (2.0.2)\n",
            "Requirement already satisfied: rdflib in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (6.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.1.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.0.1)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (3.0.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (4.62.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.11.3)\n",
            "Requirement already satisfied: googledrivedownloader in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.19.5)\n",
            "Requirement already satisfied: yacs in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.1.8)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (3.13)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.6.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric) (2.0.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->torch-geometric) (1.15.0)\n",
            "Requirement already satisfied: isodate in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric) (0.6.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric) (57.4.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (3.0.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (1.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WI18lGYPa6cV",
        "outputId": "2bb46733-ac19-4537-b6b8-6a92591c9865"
      },
      "source": [
        "pip install igraph"
      ],
      "id": "WI18lGYPa6cV",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: igraph in /usr/local/lib/python3.7/dist-packages (0.9.8)\n",
            "Requirement already satisfied: texttable>=1.6.2 in /usr/local/lib/python3.7/dist-packages (from igraph) (1.6.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08b772c5",
        "outputId": "0bafcfb3-ae4f-4565-e4ff-e9667df0ecbc"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import io\n",
        "\n",
        "import seaborn as sn\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "#from cdlib import NodeClustering, evaluation, algorithms\n",
        "import igraph as ig\n",
        "import networkx as nx\n",
        "import pickle\n",
        "\n",
        "from nltk import (corpus, tokenize, download)\n",
        "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
        "download(\"stopwords\")\n",
        "download('punkt')\n",
        "\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "\n",
        "from torch_geometric.nn import Node2Vec\n",
        "\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "sns.set_context('talk')\n"
      ],
      "id": "08b772c5",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7e5d1ee"
      },
      "source": [
        "### Cargamos el dataset"
      ],
      "id": "e7e5d1ee"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "LRnAUEB0URoc",
        "outputId": "9e4a34b0-1fc1-4a04-df7f-3a3442fc5afd"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "id": "LRnAUEB0URoc",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-de9b6178-3a6e-4aed-8563-b9dc86bdcf29\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-de9b6178-3a6e-4aed-8563-b9dc86bdcf29\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving larg_G.edgelist to larg_G (2).edgelist\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Up8sCuRGZoyS"
      },
      "source": [
        "larg_G = nx.read_edgelist('larg_G.edgelist')"
      ],
      "id": "Up8sCuRGZoyS",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtI4bJ28at8P",
        "outputId": "150f3c55-ba74-4949-866d-2cf289505c58"
      },
      "source": [
        "larg_G"
      ],
      "id": "NtI4bJ28at8P",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<networkx.classes.graph.Graph at 0x7fb631713dd0>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16eb5398-6d5a-42c9-939f-e0b50919efba"
      },
      "source": [
        "## Actividades"
      ],
      "id": "16eb5398-6d5a-42c9-939f-e0b50919efba"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3b011400-5424-4f3c-a2da-69d0c295f2d1"
      },
      "source": [
        "## 5. Embedding de nodos\n",
        "Generar un embedding del grafo de retweets utilizando el algoritmo word2vec.\n",
        "Reducir a 2 la dimensionalidad del embedding utilizando PCA y t-SNE.\n",
        "Graficar los embeddings correspondientes a los datos etiquetados. ¿Es posible diferenciar unos de otros?"
      ],
      "id": "3b011400-5424-4f3c-a2da-69d0c295f2d1"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cead150-15fd-49d2-9bc5-4038d2c15bbb",
        "outputId": "9fefeea0-bccd-4405-e544-28aadd1a78fb"
      },
      "source": [
        "## Elegimos si usar CPU o GPU para los cálculos\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using {} device\".format(device))"
      ],
      "id": "2cead150-15fd-49d2-9bc5-4038d2c15bbb",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3g4LhT83bmy8"
      },
      "source": [
        "Matrices esparsas"
      ],
      "id": "3g4LhT83bmy8"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCt7mNTpSRPu"
      },
      "source": [
        "adj = nx.to_scipy_sparse_matrix(larg_G).tocoo()\n",
        "row = torch.from_numpy(adj.row.astype(np.int64)).to(torch.long)\n",
        "col = torch.from_numpy(adj.col.astype(np.int64)).to(torch.long)\n",
        "edge_index = torch.stack([row, col], dim=0)"
      ],
      "id": "MCt7mNTpSRPu",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfdyObIhbob4"
      },
      "source": [
        "Node2Vec"
      ],
      "id": "rfdyObIhbob4"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvnGDlSgSRIw"
      },
      "source": [
        "## Definimos nuestro modelo\n",
        "model = Node2Vec(\n",
        "    edge_index, embedding_dim=100, walk_length=1000, \n",
        "    context_size=4, num_negative_samples=5\n",
        ").to(device)\n",
        "\n",
        "## El loader es un wrapper que nos permite trabajar por lotes, \n",
        "## para utilizar descenso por el gradiente estocástico y\n",
        "## sus variantes\n",
        "loader = model.loader(batch_size=128, shuffle=True)\n",
        "\n",
        "## Optimizador\n",
        "optimizer = torch.optim.Adam(list(model.parameters()), lr=0.01)"
      ],
      "id": "RvnGDlSgSRIw",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mdl1hQnbbrEI"
      },
      "source": [
        "def train():\n",
        "    ## Ponemos nuestro modelo en modo entrenamiento\n",
        "    model.train()\n",
        "\n",
        "    total_loss = 0\n",
        "    for pos_rw, neg_rw in loader:\n",
        "\n",
        "        ## Reseteamos los gradientes\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        ## Calculamos el error (la función de costo) del lote\n",
        "        ## en función de los samples positivos y negativos\n",
        "        loss = model.loss(pos_rw.to(device), neg_rw.to(device))\n",
        "\n",
        "        ## Hacemos backpropagation\n",
        "        loss.backward()\n",
        "\n",
        "        ## Avanzamos un paso\n",
        "        optimizer.step()\n",
        "\n",
        "        ## Actualizamos la función de costo total\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(loader)"
      ],
      "id": "Mdl1hQnbbrEI",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0Oik6PgcTQb",
        "outputId": "d7a516da-78e1-4c82-822d-044521c37a10"
      },
      "source": [
        "epochs = 20\n",
        "for epoch in range(epochs):\n",
        "    loss = train()\n",
        "    if epoch % 5 == 0:\n",
        "        print(f'Epoch: {epoch:3} - Loss: {loss:.3f}')"
      ],
      "id": "G0Oik6PgcTQb",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:   0 - Loss: 2.537\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5iDSY0lcYPd"
      },
      "source": [
        "def get_embedding():\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        nodes = torch.arange(larg_G.number_of_nodes(), device=device)\n",
        "        embedding = model(nodes).detach().numpy()\n",
        "    return embedding\n",
        "\n",
        "embedding = get_embedding()"
      ],
      "id": "K5iDSY0lcYPd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5vqSz6ncYIH"
      },
      "source": [
        "pca = PCA(n_components=2, random_state=22).fit_transform(embedding)\n",
        "tsne = TSNE(n_components=2, learning_rate='auto', init='pca', random_state=22).fit_transform(embedding)"
      ],
      "id": "w5vqSz6ncYIH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjCB_9ebcX8N"
      },
      "source": [
        "#def add_labels(larg_G, pos, ax):\n",
        "#   labels = [v for v in larg_G.nodes()]\n",
        "#    for i in range(larg_G.number_of_nodes()):\n",
        "#        x, y = pos[i]\n",
        "#        label = labels[i]\n",
        "#        ax.text(x, y, label)\n",
        "\n",
        "#color = ['C0' if elem == 'Mr. Hi' else 'C1' for elem in membership]\n",
        "ncols = 2\n",
        "fig, axes = plt.subplots(figsize=(8*ncols, 8), ncols=2)\n",
        "ax = axes[0]\n",
        "ax.set_xlabel(r'$x_1$')\n",
        "ax.set_ylabel(r'$x_2$')\n",
        "ax.set_title('PCA')\n",
        "ax.scatter(pca[:,0], pca[:,1])\n",
        "#add_labels(larg_G, pca, ax)\n",
        "ax = axes[1]\n",
        "ax.set_xlabel(r'$x_1$')\n",
        "ax.set_ylabel(r'$x_2$')\n",
        "ax.set_title('t-SNE')\n",
        "ax.scatter(tsne[:,0], tsne[:,1])\n",
        "#add_labels(larg_G, tsne, ax)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "UjCB_9ebcX8N",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ae525eef-7c80-4bae-b59f-3716b7140ccf"
      },
      "source": [
        "## Opcional: \n",
        "Graficar además los embeddings de los nodos que forman parte de las comunidades asociadas a cada clase. Determinar si el embedding permite distinguir cada comunidad."
      ],
      "id": "ae525eef-7c80-4bae-b59f-3716b7140ccf"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94332711-e201-4e79-93f6-7371ad099100"
      },
      "source": [
        ""
      ],
      "id": "94332711-e201-4e79-93f6-7371ad099100",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1f1bdc7-f0f3-458f-9269-e81e5fb1c08d"
      },
      "source": [
        ""
      ],
      "id": "d1f1bdc7-f0f3-458f-9269-e81e5fb1c08d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67f18638-7c99-4e5a-8609-ad214af69d67"
      },
      "source": [
        "## Opcional: 6. Redes neuronales de grafos\n",
        "El archivo word_vectors.csv contiene un embedding de 300 dimensiones para cada tweet, otenido utilizando un modelo preentrenado de FastText. Construir una matriz de features para los nodos tomando, para cada usuario, el promedio de los vectores correspondientes a los tweets que escribió. Utilizando estos features, y tomando como ejemplos etiquetados los usuarios de \"etiquetas.csv\" entrenar una red neuronal de grafos para realizar una clasificación binaria sobre el resto de los nodos. Pueden utilizar como base el siguiente modelo:"
      ],
      "id": "67f18638-7c99-4e5a-8609-ad214af69d67"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "599b1734-7eff-47b1-92dc-03cbed89e684"
      },
      "source": [
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(GCN, self).__init__()\n",
        "        torch.manual_seed(1234)\n",
        "        self.conv1 = GCNConv(dataset.num_features, 4)\n",
        "        self.conv2 = GCNConv(4, 4)\n",
        "        self.conv3 = GCNConv(4, 2)\n",
        "        self.classifier = Linear(2, dataset.num_classes)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        h = self.conv1(x, edge_index)\n",
        "        h = h.tanh()\n",
        "        h = self.conv2(h, edge_index)\n",
        "        h = h.tanh()\n",
        "        h = self.conv3(h, edge_index)\n",
        "        h = h.tanh()  # Embedding final\n",
        "        \n",
        "        # Aplicamos un clasificador lineal sobre el embedding\n",
        "        out = self.classifier(h)\n",
        "\n",
        "        return out, h"
      ],
      "id": "599b1734-7eff-47b1-92dc-03cbed89e684",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e67d6f37-b739-45db-baad-80384dbe581b"
      },
      "source": [
        "Observación: para alimentar la red neuronal, es necesario construir un objeto de la clase Dataset de PyTorch-Geometric. Una forma de hacer eso es la siguiente"
      ],
      "id": "e67d6f37-b739-45db-baad-80384dbe581b"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cf6aec5-e846-4d5b-bbdf-b31454eaa680"
      },
      "source": [
        "from torch_geometric.data import InMemoryDataset, Data\n",
        "\n",
        "## Reemplazar por el grafo correspondiente\n",
        "g = nx.Graph()\n",
        "\n",
        "## Etiquetas. Reemplazar por las clases del archivo 'etiquetas.csv'.\n",
        "## Asignar la clase '2' a los ejemplos no etiquetados\n",
        "labels = [1, 0, 2, ..., 1]\n",
        "\n",
        "## True si el ejemplo está etiquetado (clases 0 y 1)\n",
        "train_idx = [True, True, False, ..., True]\n",
        "\n",
        "## Matriz de features (word vectors)\n",
        "features = ...\n",
        "\n",
        "adj = nx.to_scipy_sparse_matrix(g).tocoo()\n",
        "row = torch.from_numpy(adj.row.astype(np.int64)).to(torch.long)\n",
        "col = torch.from_numpy(adj.col.astype(np.int64)).to(torch.long)\n",
        "edge_index = torch.stack([row, col], dim=0)\n",
        "\n",
        "\n",
        "class TwitterDataset(InMemoryDataset):\n",
        "    def __init__(self, transform=None):\n",
        "        super(TwitterDataset, self).__init__('.', transform, None, None)\n",
        "\n",
        "        data = Data(edge_index=edge_index)\n",
        "        \n",
        "        data.num_nodes = g.number_of_nodes()\n",
        "        \n",
        "        # Features \n",
        "        data.x = torch.from_numpy(features).type(torch.float32)\n",
        "        \n",
        "        # Etiquetas\n",
        "        y = torch.from_numpy(labels).type(torch.long)\n",
        "        data.y = y.clone().detach()\n",
        "        \n",
        "        data.num_classes = 2\n",
        "        \n",
        "        n_nodes = g.number_of_nodes()\n",
        "        \n",
        "        # create train and test masks for data\n",
        "        train_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
        "        train_mask[train_idx] = True\n",
        "        data['train_mask'] = train_mask\n",
        "\n",
        "        self.data, self.slices = self.collate([data])\n",
        "\n",
        "    def _download(self):\n",
        "        return\n",
        "\n",
        "    def _process(self):\n",
        "        return\n",
        "\n",
        "    def __repr__(self):\n",
        "        return '{}()'.format(self.__class__.__name__)"
      ],
      "id": "6cf6aec5-e846-4d5b-bbdf-b31454eaa680",
      "execution_count": null,
      "outputs": []
    }
  ]
}